{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#!/usr/bin/python\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reader(in_filepath):\n",
    "    \"\"\"\n",
    "    Read stoRM's log file and transform into a list of lines (str)\n",
    "    \n",
    "    Recive path (string) to unstructured log file\n",
    "    Return a list containing where each element is a log's line\n",
    "    \"\"\"\n",
    "    listed_log = []\n",
    "    \n",
    "    input_file = open(in_filepath,\"r\")\n",
    "    for line in input_file:\n",
    "        listed_log.append(line.strip())\n",
    "    input_file.close()\n",
    "    \n",
    "    return listed_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_tabler(listed_log):\n",
    "    \"\"\"\n",
    "    Transform a log's list of lines (str) in a dictionary\n",
    "    \n",
    "    Recive a list containing where each element is a (stoRM) log's line\n",
    "    Return a table (dict) where each key is a log's column\n",
    "    \"\"\"\n",
    "    #timestamp is yet to be finished\n",
    "    date, time_stamp, thread, tipe, token, message = [], [], [], [], [], []\n",
    "    it = 0\n",
    "    total = len(listed_log)\n",
    "    for line in listed_log:\n",
    "        date.append(line[:18])\n",
    "        time_stamp.append(dateparser.storm_dtpars(line[:18]))\n",
    "        thread.append(line.split(\" \",4)[3])\n",
    "        tipe.append(line.split(\" \",7)[6])\n",
    "        token.append(line.split(\"[\",1)[1].split(\"]\",1)[0])\n",
    "        message.append(line.split(\":\",3)[3].rstrip().lstrip())\n",
    "        if it%100000 == 0 :\n",
    "            print \" parsed line {0} of {1} lines\".format(it,total)\n",
    "        if it == total:\n",
    "            print \"END\"\n",
    "        it+=1\n",
    "        \n",
    "    log_table = {'DATE':date, 'TIMESTAMP':time_stamp, 'THREAD':thread,\\\n",
    "                 'TYPE':tipe, 'TOKEN':token, 'MESSAGE':message}\n",
    "    return log_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csver(log_table,out_filepath):\n",
    "    \"\"\"\n",
    "    Transform a log (dictionary) in .csv\n",
    "    \n",
    "    Recive a table (dict) where each key is a log's column\n",
    "           a string of the filepath output and file name\n",
    "    Return None\n",
    "    Produce a structured .csv file of a stoRM log file\n",
    "    \"\"\"\n",
    "    dataf = pd.DataFrame.from_dict(log_table)\n",
    "    #P: find out columns order\n",
    "    #print dataf.columns.tolist()\n",
    "    \n",
    "    #P: riarrange columns order\n",
    "    cols =['DATE', 'TIMESTAMP', 'TYPE','THREAD', 'TOKEN','MESSAGE']\n",
    "    dataf = dataf[cols]\n",
    "    \n",
    "    #print dataf.describe()\n",
    "    dataf.to_csv(out_filepath + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csver_small(log_table,out_filepath,start, end):\n",
    "    \"\"\"\n",
    "    Transform a log slice (dctionary) in .csv\n",
    "    \n",
    "    Recive a table (dict) where each key is a log's column\n",
    "           a string of the filepath output and file name\n",
    "    Return None\n",
    "    Produce a structured .csv file of a stoRM log file\n",
    "    \"\"\"\n",
    "    dataf = pd.DataFrame.from_dict(log_table)\n",
    "    #P: find out columns order\n",
    "    #print dataf.columns.tolist()\n",
    "    \n",
    "    #P: riarrange columns order\n",
    "    cols =['DATE', 'TIMESTAMP', 'TYPE','THREAD', 'TOKEN','MESSAGE']\n",
    "    dataf = dataf[cols]\n",
    "    \n",
    "    #print dataf.describe()\n",
    "    dataf[start:end].to_csv(out_filepath + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msger(log_table,filepath):\n",
    "    \"\"\"\n",
    "    Transform a log's dictionary in msgpack \n",
    "    \n",
    "    Recive a table (dict) where each key is a log's column\n",
    "           a string of the filepath output and file name\n",
    "    Return None\n",
    "    Produce a msgpack file of a stoRM log file\n",
    "    \"\"\"\n",
    "    dataf = pd.DataFrame.from_dict(log_table)\n",
    "    cols = ['DATE', 'TIMESTAMP', 'TYPE','THREAD', 'TOKEN','MESSAGE']\n",
    "    dataf = dataf[cols]\n",
    "    dataf.to_msgpack(filepath + '.msg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msger_small(log_table,filepath,start,end):\n",
    "    \"\"\"\n",
    "    Transform a log's slice dictionary in msgpack \n",
    "    \n",
    "    Recive a table (dict) where each key is a log's column\n",
    "           a string of the filepath output and file name\n",
    "    Return None\n",
    "    Produce a msgpack file of a stoRM log file\n",
    "    \"\"\"\n",
    "    dataf = pd.DataFrame.from_dict(log_table)\n",
    "    cols = ['DATE', 'TIMESTAMP', 'TYPE','THREAD', 'TOKEN','MESSAGE']\n",
    "    dataf = dataf[cols]\n",
    "    dataf[start:end].to_msgpack( filepath + '_small' + '.msg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " parsed line 0 of 16727293 lines\n",
      " parsed line 100000 of 16727293 lines\n",
      " parsed line 200000 of 16727293 lines\n",
      " parsed line 300000 of 16727293 lines\n",
      " parsed line 400000 of 16727293 lines\n",
      " parsed line 500000 of 16727293 lines\n",
      " parsed line 600000 of 16727293 lines\n",
      " parsed line 700000 of 16727293 lines\n",
      " parsed line 800000 of 16727293 lines\n",
      " parsed line 900000 of 16727293 lines\n",
      " parsed line 1000000 of 16727293 lines\n",
      " parsed line 1100000 of 16727293 lines\n",
      " parsed line 1200000 of 16727293 lines\n",
      " parsed line 1300000 of 16727293 lines\n",
      " parsed line 1400000 of 16727293 lines\n",
      " parsed line 1500000 of 16727293 lines\n",
      " parsed line 1600000 of 16727293 lines\n",
      " parsed line 1700000 of 16727293 lines\n",
      " parsed line 1800000 of 16727293 lines\n",
      " parsed line 1900000 of 16727293 lines\n",
      " parsed line 2000000 of 16727293 lines\n",
      " parsed line 2100000 of 16727293 lines\n",
      " parsed line 2200000 of 16727293 lines\n",
      " parsed line 2300000 of 16727293 lines\n",
      " parsed line 2400000 of 16727293 lines\n",
      " parsed line 2500000 of 16727293 lines\n",
      " parsed line 2600000 of 16727293 lines\n",
      " parsed line 2700000 of 16727293 lines\n",
      " parsed line 2800000 of 16727293 lines\n",
      " parsed line 2900000 of 16727293 lines\n",
      " parsed line 3000000 of 16727293 lines\n",
      " parsed line 3100000 of 16727293 lines\n",
      " parsed line 3200000 of 16727293 lines\n",
      " parsed line 3300000 of 16727293 lines\n",
      " parsed line 3400000 of 16727293 lines\n",
      " parsed line 3500000 of 16727293 lines\n",
      " parsed line 3600000 of 16727293 lines\n",
      " parsed line 3700000 of 16727293 lines\n",
      " parsed line 3800000 of 16727293 lines\n",
      " parsed line 3900000 of 16727293 lines\n",
      " parsed line 4000000 of 16727293 lines\n",
      " parsed line 4100000 of 16727293 lines\n",
      " parsed line 4200000 of 16727293 lines\n",
      " parsed line 4300000 of 16727293 lines\n",
      " parsed line 4400000 of 16727293 lines\n",
      " parsed line 4500000 of 16727293 lines\n",
      " parsed line 4600000 of 16727293 lines\n",
      " parsed line 4700000 of 16727293 lines\n",
      " parsed line 4800000 of 16727293 lines\n",
      " parsed line 4900000 of 16727293 lines\n",
      " parsed line 5000000 of 16727293 lines\n",
      " parsed line 5100000 of 16727293 lines\n",
      " parsed line 5200000 of 16727293 lines\n",
      " parsed line 5300000 of 16727293 lines\n",
      " parsed line 5400000 of 16727293 lines\n",
      " parsed line 5500000 of 16727293 lines\n",
      " parsed line 5600000 of 16727293 lines\n",
      " parsed line 5700000 of 16727293 lines\n",
      " parsed line 5800000 of 16727293 lines\n",
      " parsed line 5900000 of 16727293 lines\n",
      " parsed line 6000000 of 16727293 lines\n",
      " parsed line 6100000 of 16727293 lines\n",
      " parsed line 6200000 of 16727293 lines\n",
      " parsed line 6300000 of 16727293 lines\n",
      " parsed line 6400000 of 16727293 lines\n",
      " parsed line 6500000 of 16727293 lines\n",
      " parsed line 6600000 of 16727293 lines\n",
      " parsed line 6700000 of 16727293 lines\n",
      " parsed line 6800000 of 16727293 lines\n",
      " parsed line 6900000 of 16727293 lines\n",
      " parsed line 7000000 of 16727293 lines\n",
      " parsed line 7100000 of 16727293 lines\n",
      " parsed line 7200000 of 16727293 lines\n",
      " parsed line 7300000 of 16727293 lines\n",
      " parsed line 7400000 of 16727293 lines\n",
      " parsed line 7500000 of 16727293 lines\n",
      " parsed line 7600000 of 16727293 lines\n",
      " parsed line 7700000 of 16727293 lines\n",
      " parsed line 7800000 of 16727293 lines\n",
      " parsed line 7900000 of 16727293 lines\n",
      " parsed line 8000000 of 16727293 lines\n",
      " parsed line 8100000 of 16727293 lines\n",
      " parsed line 8200000 of 16727293 lines\n",
      " parsed line 8300000 of 16727293 lines\n",
      " parsed line 8400000 of 16727293 lines\n",
      " parsed line 8500000 of 16727293 lines\n",
      " parsed line 8600000 of 16727293 lines\n",
      " parsed line 8700000 of 16727293 lines\n",
      " parsed line 8800000 of 16727293 lines\n",
      " parsed line 8900000 of 16727293 lines\n",
      " parsed line 9000000 of 16727293 lines\n",
      " parsed line 9100000 of 16727293 lines\n",
      " parsed line 9200000 of 16727293 lines\n",
      " parsed line 9300000 of 16727293 lines\n",
      " parsed line 9400000 of 16727293 lines\n",
      " parsed line 9500000 of 16727293 lines\n",
      " parsed line 9600000 of 16727293 lines\n",
      " parsed line 9700000 of 16727293 lines\n",
      " parsed line 9800000 of 16727293 lines\n",
      " parsed line 9900000 of 16727293 lines\n",
      " parsed line 10000000 of 16727293 lines\n",
      " parsed line 10100000 of 16727293 lines\n",
      " parsed line 10200000 of 16727293 lines\n",
      " parsed line 10300000 of 16727293 lines\n",
      " parsed line 10400000 of 16727293 lines\n",
      " parsed line 10500000 of 16727293 lines\n",
      " parsed line 10600000 of 16727293 lines\n",
      " parsed line 10700000 of 16727293 lines\n",
      " parsed line 10800000 of 16727293 lines\n",
      " parsed line 10900000 of 16727293 lines\n",
      " parsed line 11000000 of 16727293 lines\n",
      " parsed line 11100000 of 16727293 lines\n",
      " parsed line 11200000 of 16727293 lines\n",
      " parsed line 11300000 of 16727293 lines\n",
      " parsed line 11400000 of 16727293 lines\n",
      " parsed line 11500000 of 16727293 lines\n",
      " parsed line 11600000 of 16727293 lines\n",
      " parsed line 11700000 of 16727293 lines\n",
      " parsed line 11800000 of 16727293 lines\n",
      " parsed line 11900000 of 16727293 lines\n",
      " parsed line 12000000 of 16727293 lines\n",
      " parsed line 12100000 of 16727293 lines\n",
      " parsed line 12200000 of 16727293 lines\n",
      " parsed line 12300000 of 16727293 lines\n",
      " parsed line 12400000 of 16727293 lines\n",
      " parsed line 12500000 of 16727293 lines\n",
      " parsed line 12600000 of 16727293 lines\n",
      " parsed line 12700000 of 16727293 lines\n",
      " parsed line 12800000 of 16727293 lines\n",
      " parsed line 12900000 of 16727293 lines\n",
      " parsed line 13000000 of 16727293 lines\n",
      " parsed line 13100000 of 16727293 lines\n",
      " parsed line 13200000 of 16727293 lines\n",
      " parsed line 13300000 of 16727293 lines\n",
      " parsed line 13400000 of 16727293 lines\n",
      " parsed line 13500000 of 16727293 lines\n",
      " parsed line 13600000 of 16727293 lines\n",
      " parsed line 13700000 of 16727293 lines\n",
      " parsed line 13800000 of 16727293 lines\n",
      " parsed line 13900000 of 16727293 lines\n",
      " parsed line 14000000 of 16727293 lines\n",
      " parsed line 14100000 of 16727293 lines\n",
      " parsed line 14200000 of 16727293 lines\n",
      " parsed line 14300000 of 16727293 lines\n",
      " parsed line 14400000 of 16727293 lines\n",
      " parsed line 14500000 of 16727293 lines\n",
      " parsed line 14600000 of 16727293 lines\n",
      " parsed line 14700000 of 16727293 lines\n",
      " parsed line 14800000 of 16727293 lines\n",
      " parsed line 14900000 of 16727293 lines\n",
      " parsed line 15000000 of 16727293 lines\n",
      " parsed line 15100000 of 16727293 lines\n",
      " parsed line 15200000 of 16727293 lines\n",
      " parsed line 15300000 of 16727293 lines\n",
      " parsed line 15400000 of 16727293 lines\n",
      " parsed line 15500000 of 16727293 lines\n",
      " parsed line 15600000 of 16727293 lines\n",
      " parsed line 15700000 of 16727293 lines\n",
      " parsed line 15800000 of 16727293 lines\n",
      " parsed line 15900000 of 16727293 lines\n",
      " parsed line 16000000 of 16727293 lines\n",
      " parsed line 16100000 of 16727293 lines\n",
      " parsed line 16200000 of 16727293 lines\n",
      " parsed line 16300000 of 16727293 lines\n",
      " parsed line 16400000 of 16727293 lines\n",
      " parsed line 16500000 of 16727293 lines\n",
      " parsed line 16600000 of 16727293 lines\n",
      " parsed line 16700000 of 16727293 lines\n",
      "CPU times: user 9min 46s, sys: 12.8 s, total: 9min 59s\n",
      "Wall time: 10min 2s\n"
     ]
    }
   ],
   "source": [
    "%time msger_small(log_tabler(log_reader(\"log_non_strutturati/storm-frontend-server.log-20180901\")),\"log_non_strutturati/storm-frontend-server.log-20180901\",0,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(16ML lines log)<br>\n",
    "csver => CPU times: user 11min 48s, sys: 17.7 s, total: 12min 6s Wall time: 12min 10s <br> msper => CPU times: user 10min 44s, sys: 18.7 s, total: 11min 2s Wall time: 11min 10s\n",
    "<br>\n",
    "<span style='color:red'> Un grosso gap da risolvere è che comunque anche per creare log strutturati parziali con il codice fatto in questo modo noi ci parsiamo prima tutto il codice, **anche perche ci giochiamo facile 14gb di ram**, il che non è esatamente una cosa efficente. In un momento del tempo cambia questa cosa. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test per importazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg_to_df(file_path):\n",
    "    storm_df = pd.read_msgpack(file_path)\n",
    "    return storm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(file_path):\n",
    "    storm_df = pd.read_csv(file_path)\n",
    "    return storm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time a = msg_to_df(\"/home/gabriele/Documenti/storm-frontend-server.log-20180901.msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time b = csv_to_df(\"/home/gabriele/Documenti/storm-frontend-server.log-20180901.csv\",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
